{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Popularity                                       Page content\n",
      "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
      "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
      "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
      "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
      "4   4          -1  <html><head><div class=\"article-info\"><span cl...\n",
      "      Id                                       Page content\n",
      "0  27643  <html><head><div class=\"article-info\"><span cl...\n",
      "1  27644  <html><head><div class=\"article-info\"><span cl...\n",
      "2  27645  <html><head><div class=\"article-info\"><span cl...\n",
      "3  27646  <html><head><div class=\"article-info\"><span cl...\n",
      "4  27647  <html><head><div class=\"article-info\"><span cl...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/comp1/train.csv')\n",
    "print(df.head(5))\n",
    "df_test = pd.read_csv('./data/comp1/test.csv')\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup(text):\n",
    "    # remove HTML tags\n",
    "    return BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "def select_tag(text, tag):\n",
    "    # remove HTML tags\n",
    "    return BeautifulSoup(text, 'html.parser').select(tag)[0].text.strip()\n",
    "\n",
    "def preprocessor(text):\n",
    "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "    r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(r, text)\n",
    "    text = re.sub(r, '', text)\n",
    "    \n",
    "    # convert to lowercase and append all emoticons behind (with space in between)\n",
    "    # replace('-','') removes nose of emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAuthor(soup):\n",
    "    if len(soup.select('.author_name a')) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return soup.select('.author_name a')[0].text\n",
    "    \n",
    "def flatten(arr_2D):\n",
    "    result = []\n",
    "    for arr in arr_2D:\n",
    "        if len(arr) == 0:\n",
    "            result.append(np.nan)\n",
    "        else:\n",
    "            result.append(arr.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = df['Page content'].map(lambda x: soup(x))\n",
    "df['author'] = df['result'].map(lambda x: checkAuthor(x))\n",
    "df['time'] = df['result'].map(lambda x: x.select('time')[0].text)\n",
    "df['time'] = df['time'].map(lambda x : datetime.datetime.strptime(x[:19], '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "df['topic'] = df['result'].map(lambda x: x.select('.article-topics a'))\n",
    "df['image num'] = df['result'].map(lambda x: len(x.select('img')))\n",
    "df['video num'] = df['result'].map(lambda x: len(x.select('iframe')))\n",
    "df['body'] = df['result'].map(lambda x: x.select('body')[0].text.strip())\n",
    "\n",
    "df['topic'] = df['topic'].map(lambda x: flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week of day'] = df['time'].map(lambda x: x.isoweekday() )\n",
    "df['year'] = df['time'].map(lambda x: x.year )\n",
    "df['month'] = df['time'].map(lambda x: x.month )\n",
    "df['hour'] = df['time'].map(lambda x: x.hour )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekend'] = df['week of day']\n",
    "mask = df['weekend'] > 5 \n",
    "df.loc[mask, 'weekend'] = 1\n",
    "df.loc[~mask, 'weekend'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['result']).to_csv('data/train_new_feature1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 2056) (27643,) (11847, 2056) (11847, 2056)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('objs_topic_featurehash.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    doc_hash, doc_y_label, doc_hash_test, doc_hash_test_np = pickle.load(f)\n",
    "print(doc_hash.shape, doc_y_label.shape, doc_hash_test.shape, doc_hash_test_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `objs_topic_featurehash.plk` contains:\n",
    "1. **body (1024-dim)**: Capture the content in `<body>`, transform to vector by `HashingVectorizer()` with TA's `preprocessor()` and `tokenizer_stem_nostop()`.\n",
    "2. **topic (1024-dim)**: Capture the content in `<topic>`, transform to vector by `HashingVectorizer()` with TA's `preprocessor()` and `tokenizer_stem_nostop()`.\n",
    "3. **author (1-dim)**: Capture the content in `<a href=\"/author/.../\">`, encode every author with an unique ID.\n",
    "4. **img num (1-dim)**: Count the number of `<img>`.\n",
    "5. **video num (1-dim)**: Count the number of `<video>`.\n",
    "6. **week of day (1-dim)**: Map \"Monday\" to \"1\", \"Tuesday\" to \"2\", ..., \"Sunday\" to \"7\". \n",
    "7. **weekend (1-dim)**: 1 if `week of day` is bigger than 5, else 0.\n",
    "8. **month (1-dim)**: a number range from 1 to 12.\n",
    "9. **hour (1-dim)**: a number range from 0 to 23.\n",
    "10. **year (1-dim)**: a number of year.<br>\n",
    "\n",
    ", which is total 2056 dimemsions. We import it for further preprocessing as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature 1: Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Id (1-dim)** just for anchoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id(1) (27643, 1)\n",
      "Id(1) (11847, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_feature_x = np.array(df['Id']).reshape(-1,1)\n",
    "print(\"Id(1)\", new_feature_x.shape)\n",
    "\n",
    "new_feature_x_test = np.array(df_test['Id']).reshape(-1,1)\n",
    "print(\"Id(1)\", new_feature_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature 2: body&topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**body&topic (201-dim)** <br>\n",
    "Further preprocess the **body (1024-dim)** and **topic (1024-dim)** in `objs_topic_featurehash.plk` by choosing the important dimensions that have bigger than 0.01 correlation with the Popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 2048)\n",
      "(27643, 1)\n",
      "(27643, 2049)\n",
      "202\n",
      "[6, 11, 16, 17, 26, 27, 33, 48, 52, 65, 73, 74, 102, 117, 120, 124, 164, 169, 172, 175, 190, 196, 198, 202, 230, 239, 250, 258, 273, 274, 310, 316, 330, 337, 355, 397, 412, 426, 459, 482, 500, 507, 515, 523, 524, 525, 531, 536, 543, 546, 567, 569, 572, 586, 590, 604, 608, 619, 621, 648, 649, 665, 699, 700, 704, 714, 724, 761, 765, 768, 769, 781, 782, 790, 799, 806, 820, 827, 838, 844, 847, 880, 882, 884, 887, 888, 895, 896, 897, 898, 901, 912, 913, 919, 936, 949, 953, 958, 987, 991, 1000, 1003, 1011, 1018, 1020, 1021, 1032, 1035, 1041, 1051, 1076, 1077, 1080, 1085, 1143, 1174, 1214, 1246, 1263, 1328, 1329, 1334, 1339, 1340, 1347, 1354, 1361, 1379, 1400, 1423, 1436, 1446, 1447, 1450, 1461, 1483, 1506, 1524, 1531, 1539, 1544, 1548, 1562, 1570, 1573, 1591, 1603, 1606, 1610, 1611, 1618, 1625, 1627, 1628, 1632, 1641, 1643, 1655, 1668, 1669, 1673, 1678, 1687, 1719, 1723, 1730, 1739, 1780, 1787, 1789, 1797, 1816, 1827, 1832, 1834, 1840, 1844, 1845, 1851, 1862, 1865, 1868, 1870, 1876, 1887, 1889, 1904, 1935, 1936, 1937, 1940, 1943, 1944, 1952, 1988, 2017, 2024, 2031, 2040, 2042, 2045, 2048]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler # scikit-learn 0.21.3\n",
    "import seaborn as sns # seaborn 0.9.0\n",
    "x = doc_hash.toarray()[:,:-8]\n",
    "print(x.shape)\n",
    "print(np.array(df['Popularity']).reshape(-1,1).shape)\n",
    "x = np.append(x,np.array(df['Popularity']).reshape(-1,1),axis=1)\n",
    "print(x.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Z = sc.fit_transform(x)\n",
    "# Estimate the correlation matrix\n",
    "R = np.dot(Z.T, Z) / df.shape[0]\n",
    "\n",
    "reshape = []\n",
    "for idx, item in enumerate(R[-1]):\n",
    "    if item>0.01: # find the important component in body&topic: 2048-dim\n",
    "        reshape.append(idx)\n",
    "print(len(reshape))\n",
    "print(reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line 4 **\"202\"** of the above result means there's only 201+1 dimensions that have bigger than 0.01 correlation with the Popularity (the \"+1\" indicates the correlation between Popularity and Popularity, which should not count in). Therefore, we reconstruct original 2048 dimensions to 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, sc, Z, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body&topic: 2048 to 201 (27643, 202)\n",
      "body&topic: 2048 to 201 (11847, 202)\n"
     ]
    }
   ],
   "source": [
    "for i in reshape[:-1]: # drop the high correlation between Popularity and Popularity\n",
    "    new_feature_x = np.append(new_feature_x, doc_hash.toarray()[:,i].reshape(-1,1),axis=1)\n",
    "    new_feature_x_test =  np.append(new_feature_x_test, doc_hash_test.toarray()[:,i].reshape(-1,1),axis=1)\n",
    "print('body&topic: 2048 to 201',new_feature_x.shape)\n",
    "print('body&topic: 2048 to 201',new_feature_x_test.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature 3: week of day and weekend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**week of day (1-dim)**: Map \"Monday\" to \"1\", \"Tuesday\" to \"2\", ..., \"Sunday\" to \"7\".<br>\n",
    "**weekend (1-dim)**: 1 if week of day is bigger than 5, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week of day(1) weekend(1) (27643, 204)\n",
      "week of day(1) weekend(1) (11847, 204)\n"
     ]
    }
   ],
   "source": [
    "new_feature_x = np.append(new_feature_x, doc_hash.toarray()[:,-5:-3],axis=1)\n",
    "print('week of day(1)', 'weekend(1)',new_feature_x.shape)\n",
    "new_feature_x_test = np.append(new_feature_x_test, doc_hash_test.toarray()[:,-5:-3],axis=1)\n",
    "print('week of day(1)', 'weekend(1)',new_feature_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature 4: toEndOfYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**toEndOfYear (1-dim)**: the numbers of remain days from the date of the articale to 12/31 of the same year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toEndOfYear(1) (27643, 205)\n",
      "toEndOfYear(1) (11847, 205)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime,date\n",
    "toEndOfYear = []\n",
    "for i in df['Page content']:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    time = list(soup.find('time'))[0].split(' ')\n",
    "    now = datetime.strptime(time[0], \"%Y-%m-%d\").date()\n",
    "    endOfYear = date(now.year,12,31)\n",
    "    toEndOfYear.append((endOfYear - now).days)    \n",
    "new_feature_x = np.append(new_feature_x, np.array(toEndOfYear).reshape(-1,1),axis=1)\n",
    "print('toEndOfYear(1)',new_feature_x.shape)\n",
    "\n",
    "toEndOfYear_test = []\n",
    "for i in df_test['Page content']:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    if len(list(soup.find('time'))) != 0:\n",
    "        time = list(soup.find('time'))[0].split(' ')\n",
    "        now = datetime.strptime(time[0], \"%Y-%m-%d\").date()\n",
    "        endOfYear = date(now.year,12,31)\n",
    "        toEndOfYear_test.append((endOfYear - now).days)\n",
    "    else:\n",
    "        toEndOfYear_test.append(int(178))\n",
    "new_feature_x_test = np.append(new_feature_x_test, np.array(toEndOfYear_test).reshape(-1,1),axis=1)\n",
    "print('toEndOfYear(1)',new_feature_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del toEndOfYear, toEndOfYear_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature 5: title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simialr preprocess to the **body&topic (201-dim)**, we \n",
    "1. capture the content in `<h1>`\n",
    "2. transform to 1024-dim vectors by `HashingVectorizer()` with TA's `preprocessor()` and `tokenizer_stem_nostop()`\n",
    "3. choosing the important dimensions that have bigger than 0.01 correlation with the Popularity\n",
    "4. reconstruct features from 1024 dimensions to 76 dimensions.<br>\n",
    "\n",
    "Therefore, we have **title (76-dim)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27643\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime,date\n",
    "title = []\n",
    "for i in df['Page content']:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    t = list(soup.find('h1'))[0]\n",
    "    title.append(t)\n",
    "\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11847\n"
     ]
    }
   ],
   "source": [
    "title_test = []\n",
    "for i in df_test['Page content']:\n",
    "    soup = BeautifulSoup(i, 'html.parser')\n",
    "    t = list(soup.find('h1'))[0]\n",
    "    title_test.append(t)\n",
    "\n",
    "print(len(title_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocessor(text):\n",
    "    # remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "    r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(r, text)\n",
    "    text = re.sub(r, '', text)\n",
    "    \n",
    "    # convert to lowercase and append all emoticons behind (with space in between)\n",
    "    # replace('-','') removes nose of emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "    return text\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer_stem_nostop(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "# print(tokenizer_stem_nostop('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 1024)\n",
      "(27643, 1025)\n",
      "77\n",
      "[3, 7, 11, 25, 27, 29, 45, 49, 52, 73, 99, 100, 120, 150, 164, 169, 173, 175, 190, 196, 198, 239, 258, 274, 298, 310, 316, 337, 340, 366, 389, 410, 416, 421, 440, 451, 459, 464, 467, 468, 482, 486, 489, 491, 492, 507, 515, 525, 536, 569, 586, 590, 603, 619, 636, 649, 651, 701, 737, 743, 747, 760, 761, 765, 785, 837, 842, 881, 884, 901, 930, 953, 956, 968, 1012, 1021, 1024]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hashvec = HashingVectorizer(n_features=2**10,\n",
    "                            preprocessor=preprocessor,\n",
    "                            tokenizer=tokenizer_stem_nostop)\n",
    "\n",
    "title_hash = hashvec.transform(title).toarray()\n",
    "print(title_hash.shape)\n",
    "title_hash = np.append(title_hash,np.array(df['Popularity']).reshape(-1,1),axis=1)\n",
    "print(title_hash.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Z = sc.fit_transform(title_hash)\n",
    "# Estimate the correlation matrix\n",
    "R = np.dot(Z.T, Z) / df.shape[0]\n",
    "\n",
    "reshape = []\n",
    "for idx, item in enumerate(R[-1]):\n",
    "    if item>0.01: # find the important component in body&topic: 2048-dim\n",
    "        reshape.append(idx)\n",
    "print(len(reshape))\n",
    "print(reshape)\n",
    "\n",
    "# new_feature_x = np.append(new_feature_x, title_hash.toarray(),axis=1)\n",
    "# print('title(32)',new_feature_x.shape)\n",
    "# title_hash_test = hashvec.transform(title_test)\n",
    "# new_feature_x_test = np.append(new_feature_x_test, title_hash_test.toarray(),axis=1)\n",
    "# print('title(32)',new_feature_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 1024 to 76 (27643, 281)\n",
      "title: 1024 to 76 (11847, 281)\n"
     ]
    }
   ],
   "source": [
    "title_hash_test = hashvec.transform(title_test).toarray()\n",
    "\n",
    "for i in reshape[:-1]: # drop the high correlation between Popularity and Popularity\n",
    "    new_feature_x = np.append(new_feature_x, title_hash[:,i].reshape(-1,1),axis=1)\n",
    "    new_feature_x_test =  np.append(new_feature_x_test, title_hash_test[:,i].reshape(-1,1),axis=1)\n",
    "print('title: 1024 to 76',new_feature_x.shape)\n",
    "print('title: 1024 to 76',new_feature_x_test.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summary, we have **total 281-dim features**, including\n",
    "1. **Id (1-dim)**\n",
    "2. **body&topic (201-dim)**\n",
    "3. **week of day (1-dim) and weekend (1-dim)**\n",
    "4. **toEndOfYear (1-dim)**\n",
    "5. **title (76-dim)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 25, 'n_estimators': 800} score:  0.5900676817530393\n",
      "{'mean_fit_time': array([102.97859445]), 'std_fit_time': array([9.31561422]), 'mean_score_time': array([0.66583064]), 'std_score_time': array([0.11241634]), 'param_max_depth': masked_array(data=[25],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[800],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 25, 'n_estimators': 800}], 'split0_test_score': array([0.58281796]), 'split1_test_score': array([0.61291683]), 'split2_test_score': array([0.57444463]), 'split3_test_score': array([0.58128273]), 'split4_test_score': array([0.58679865]), 'split5_test_score': array([0.60446081]), 'split6_test_score': array([0.56437991]), 'split7_test_score': array([0.59127717]), 'split8_test_score': array([0.61267892]), 'split9_test_score': array([0.5896192]), 'mean_test_score': array([0.59006768]), 'std_test_score': array([0.01512131]), 'rank_test_score': array([1])}\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10], 'probability': [True, True]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters, n_jobs=-1, cv=10, scoring='roc_auc')\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {'n_estimators':[800],\"max_depth\": [25]}\n",
    "clf = GridSearchCV(rf, parameters, n_jobs=-1, cv=10, scoring='roc_auc')\n",
    "\n",
    "clf.fit(new_feature_x, doc_y_label)\n",
    "print(clf.best_params_, \"score: \", clf.best_score_)\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here only shows one set of parameters ('max_depth': 25, 'n_estimators': 800), which is selected among all other settings we have run in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NaN in testing data and predict it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a testing data without datetime information, which would cause NaN in our program. Therefore, we remove it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585 202 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-19593a7135b0>:6: DeprecationWarning: Assigning the 'data' attribute is an inherently unsafe operation and will be removed in the future.\n",
      "  new_feature_x_test.data = np.nan_to_num(new_feature_x_test.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id  Popularity\n",
      "0  27643    0.459656\n",
      "1  27644    0.430134\n",
      "2  27645    0.448130\n",
      "3  27646    0.509935\n",
      "4  27647    0.463551\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(new_feature_x_test):\n",
    "    for idxx,j in enumerate(i):\n",
    "        if np.isnan(j):\n",
    "            print(idx,idxx,j)\n",
    "            \n",
    "new_feature_x_test.data = np.nan_to_num(new_feature_x_test.data)\n",
    "\n",
    "for idx,i in enumerate(new_feature_x_test):\n",
    "    for idxx,j in enumerate(i):\n",
    "        if np.isnan(j):\n",
    "            print(idx,idxx,j)\n",
    "\n",
    "pred = clf.predict_proba(new_feature_x_test) # predict the proba of -1 and 1\n",
    "df_all_pred = pd.concat([df_test['Id'],pd.DataFrame(pred[:,1])], axis=1).rename(columns={0: 'Popularity'})\n",
    "print(df_all_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pred.to_csv('./data/comp1/RF_281-dim_pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the correlation between each dimension of 281 features and Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 282)\n",
      "[0.00119136 0.01400685 0.01744375 0.01534015 0.01646194 0.01276709\n",
      " 0.01276669 0.01121084 0.01037327 0.01984503 0.01390659 0.02034764\n",
      " 0.01546031 0.01196157 0.01061204 0.01169194 0.0297663  0.01191991\n",
      " 0.01243966 0.01056702 0.02518365 0.01089286 0.01329412 0.01022101\n",
      " 0.01005112 0.0147265  0.01127935 0.01420136 0.0112382  0.01312126\n",
      " 0.01850545 0.0213941  0.02931966 0.01180224 0.01042016 0.01196934\n",
      " 0.01242626 0.01369141 0.01167228 0.01118573 0.01749977 0.01718265\n",
      " 0.02949877 0.02473368 0.01405626 0.02383778 0.02101989 0.01326183\n",
      " 0.01091284 0.01175075 0.01303808 0.01008893 0.01366026 0.01325441\n",
      " 0.02392093 0.01442492 0.02084844 0.01546183 0.01565638 0.01504191\n",
      " 0.01037914 0.01433222 0.01092801 0.0152073  0.01066242 0.01059173\n",
      " 0.01009319 0.01168651 0.02008007 0.01123014 0.0172594  0.011718\n",
      " 0.01018936 0.01131505 0.01020091 0.01136684 0.01329954 0.02030138\n",
      " 0.01109559 0.01351797 0.01274761 0.01022145 0.01012965 0.01492103\n",
      " 0.01263453 0.01101768 0.01103788 0.01569743 0.01185841 0.01553538\n",
      " 0.01063463 0.01126045 0.01585094 0.01162258 0.01943858 0.01912739\n",
      " 0.0145739  0.01834593 0.01819807 0.01018414 0.01100997 0.01893955\n",
      " 0.01255045 0.02126413 0.01462209 0.01123306 0.01260647 0.0148661\n",
      " 0.01215549 0.01113705 0.01053623 0.01416345 0.01009081 0.01634507\n",
      " 0.0125281  0.01125882 0.01297143 0.0157122  0.01337868 0.01416131\n",
      " 0.02588792 0.01180401 0.03974254 0.01331281 0.0164119  0.01104568\n",
      " 0.01237159 0.01565504 0.01383932 0.01151681 0.01001165 0.02087986\n",
      " 0.01611408 0.01442363 0.01204978 0.01210003 0.0146382  0.01405928\n",
      " 0.03750665 0.02186343 0.01483253 0.01022067 0.01778138 0.01113524\n",
      " 0.01278285 0.01169636 0.01025573 0.01080643 0.01030136 0.01082237\n",
      " 0.01578231 0.01166589 0.01941846 0.01145456 0.03196042 0.01260014\n",
      " 0.01171668 0.01423286 0.02105937 0.01137188 0.01307023 0.01864568\n",
      " 0.01407653 0.01090262 0.01180649 0.01625877 0.0107149  0.011664\n",
      " 0.01067347 0.01391551 0.01896172 0.02872827 0.01044871 0.01216535\n",
      " 0.01052581 0.01056565 0.01687956 0.03015395 0.01102778 0.01139776\n",
      " 0.01360972 0.01200256 0.01475082 0.02136386 0.01072036 0.01182498\n",
      " 0.01337    0.01674668 0.01025951 0.0200002  0.0181042  0.01134125\n",
      " 0.01910527 0.02029112 0.01321904 0.0101317  0.01128819 0.01681129\n",
      " 0.01175284 0.01002506 0.01120642 0.01185344 0.08554834 0.09756133\n",
      " 0.07512521 0.01184106 0.01039375 0.01283751 0.01495914 0.01008054\n",
      " 0.0138099  0.01049744 0.0111391  0.01245785 0.01372192 0.01270203\n",
      " 0.01046452 0.01343291 0.01226372 0.01294746 0.01042524 0.01268742\n",
      " 0.01107284 0.01856171 0.01318341 0.01157274 0.01529243 0.02239325\n",
      " 0.01411232 0.01015325 0.01319537 0.01115876 0.01533866 0.01348304\n",
      " 0.01161582 0.01048938 0.01217521 0.01225763 0.01540023 0.01277865\n",
      " 0.01074428 0.01241994 0.01094903 0.01130108 0.01697591 0.01185379\n",
      " 0.01022099 0.01437193 0.01142256 0.01647313 0.0272623  0.01186878\n",
      " 0.0134361  0.0135229  0.01822771 0.01597767 0.01251564 0.01112703\n",
      " 0.01209765 0.01065007 0.01134872 0.01132964 0.01848311 0.01192277\n",
      " 0.01047131 0.01142638 0.01271133 0.01347639 0.01393309 0.01111853\n",
      " 0.0109065  0.01006574 0.01097307 0.01126744 0.0100492  0.01077079\n",
      " 0.01223077 0.01666133 0.01198589 0.01123118 0.01155405 1.        ]\n"
     ]
    }
   ],
   "source": [
    "x = np.append(new_feature_x,np.array(df['Popularity']).reshape(-1,1),axis=1)\n",
    "print(x.shape)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Z = sc.fit_transform(x)\n",
    "# Estimate the correlation matrix\n",
    "R = np.dot(Z.T, Z) / df.shape[0]\n",
    "\n",
    "print(R[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the matrix above, expect the first dimension (indicating **Id (1-dim)**), there's no dimension that have lower than 0.01 correlation against Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the importance rank of 281 dimensions in RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=800,\n",
       "                       n_jobs=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=800, \n",
    "                                max_depth=25,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(new_feature_x, doc_y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) toEndOfYear                    0.036051\n",
      " 2) Id                             0.020217\n",
      " 3) week of day                    0.019970\n",
      " 4) body&topic5                    0.017210\n",
      " 5) body&topic31                   0.015457\n",
      " 6) body&topic100                  0.014522\n",
      " 7) body&topic33                   0.013580\n",
      " 8) body&topic70                   0.012262\n",
      " 9) body&topic88                   0.011927\n",
      "10) weekend                        0.011800\n",
      "11) body&topic8                    0.011777\n",
      "12) body&topic9                    0.011720\n",
      "13) body&topic37                   0.011459\n",
      "14) body&topic93                   0.011354\n",
      "15) body&topic42                   0.011285\n",
      "16) body&topic50                   0.010917\n",
      "17) body&topic87                   0.010864\n",
      "18) body&topic62                   0.010859\n",
      "19) body&topic81                   0.010814\n",
      "20) body&topic82                   0.010799\n",
      "21) body&topic28                   0.010606\n",
      "22) body&topic83                   0.010595\n",
      "23) body&topic36                   0.010411\n",
      "24) body&topic68                   0.010405\n",
      "25) body&topic11                   0.010352\n",
      "26) body&topic26                   0.010273\n",
      "27) body&topic15                   0.010269\n",
      "28) body&topic65                   0.010234\n",
      "29) body&topic49                   0.010122\n",
      "30) body&topic24                   0.010049\n",
      "31) body&topic101                  0.010006\n",
      "32) body&topic60                   0.009882\n",
      "33) body&topic41                   0.009595\n",
      "34) body&topic30                   0.009524\n",
      "35) body&topic96                   0.009397\n",
      "36) body&topic53                   0.009375\n",
      "37) body&topic2                    0.009368\n",
      "38) body&topic6                    0.009356\n",
      "39) body&topic45                   0.009334\n",
      "40) body&topic57                   0.009324\n",
      "41) body&topic74                   0.009226\n",
      "42) body&topic0                    0.009183\n",
      "43) body&topic51                   0.009165\n",
      "44) body&topic84                   0.008668\n",
      "45) body&topic27                   0.008655\n",
      "46) body&topic7                    0.008570\n",
      "47) body&topic13                   0.008569\n",
      "48) body&topic25                   0.008516\n",
      "49) body&topic52                   0.008425\n",
      "50) body&topic69                   0.008084\n",
      "51) body&topic39                   0.007936\n",
      "52) body&topic48                   0.007867\n",
      "53) body&topic59                   0.007746\n",
      "54) body&topic66                   0.007730\n",
      "55) body&topic29                   0.007659\n",
      "56) body&topic103                  0.007496\n",
      "57) body&topic71                   0.007441\n",
      "58) body&topic35                   0.007405\n",
      "59) body&topic102                  0.007267\n",
      "60) body&topic170                  0.007156\n",
      "61) body&topic55                   0.007152\n",
      "62) body&topic61                   0.007072\n",
      "63) body&topic94                   0.007069\n",
      "64) body&topic85                   0.007030\n",
      "65) body&topic20                   0.007021\n",
      "66) body&topic10                   0.006963\n",
      "67) body&topic99                   0.006924\n",
      "68) body&topic4                    0.006918\n",
      "69) body&topic75                   0.006798\n",
      "70) body&topic79                   0.006754\n",
      "71) body&topic90                   0.006714\n",
      "72) body&topic76                   0.006501\n",
      "73) body&topic95                   0.006357\n",
      "74) body&topic44                   0.006348\n",
      "75) body&topic18                   0.006296\n",
      "76) body&topic63                   0.006073\n",
      "77) body&topic97                   0.006048\n",
      "78) body&topic17                   0.006022\n",
      "79) body&topic67                   0.006003\n",
      "80) body&topic58                   0.005863\n",
      "81) body&topic22                   0.005856\n",
      "82) body&topic40                   0.005823\n",
      "83) body&topic38                   0.005801\n",
      "84) body&topic32                   0.005748\n",
      "85) body&topic92                   0.005500\n",
      "86) body&topic16                   0.005448\n",
      "87) body&topic121                  0.005235\n",
      "88) body&topic98                   0.005098\n",
      "89) body&topic56                   0.005035\n",
      "90) body&topic160                  0.005010\n",
      "91) body&topic86                   0.004919\n",
      "92) body&topic21                   0.004865\n",
      "93) body&topic191                  0.004510\n",
      "94) body&topic12                   0.004352\n",
      "95) body&topic14                   0.004124\n",
      "96) body&topic78                   0.004059\n",
      "97) body&topic105                  0.004005\n",
      "98) body&topic23                   0.003957\n",
      "99) body&topic77                   0.003895\n",
      "100) body&topic19                   0.003886\n",
      "101) body&topic43                   0.003706\n",
      "102) body&topic89                   0.003668\n",
      "103) body&topic54                   0.003580\n",
      "104) body&topic199                  0.003526\n",
      "105) body&topic47                   0.003481\n",
      "106) body&topic137                  0.003300\n",
      "107) body&topic1                    0.003259\n",
      "108) body&topic46                   0.003210\n",
      "109) body&topic34                   0.003189\n",
      "110) body&topic91                   0.003117\n",
      "111) body&topic80                   0.003106\n",
      "112) body&topic3                    0.003074\n",
      "113) body&topic192                  0.003066\n",
      "114) body&topic176                  0.002874\n",
      "115) body&topic117                  0.002802\n",
      "116) body&topic104                  0.002643\n",
      "117) body&topic72                   0.002612\n",
      "118) body&topic175                  0.002555\n",
      "119) body&topic64                   0.002459\n",
      "120) body&topic133                  0.002424\n",
      "121) body&topic138                  0.002074\n",
      "122) body&topic151                  0.001950\n",
      "123) title45                        0.001852\n",
      "124) body&topic169                  0.001811\n",
      "125) body&topic119                  0.001771\n",
      "126) body&topic189                  0.001622\n",
      "127) body&topic73                   0.001604\n",
      "128) body&topic112                  0.001510\n",
      "129) body&topic141                  0.001502\n",
      "130) body&topic122                  0.001465\n",
      "131) body&topic131                  0.001422\n",
      "132) body&topic139                  0.001309\n",
      "133) title63                        0.001202\n",
      "134) body&topic153                  0.001176\n",
      "135) title27                        0.001154\n",
      "136) title25                        0.000980\n",
      "137) title26                        0.000857\n",
      "138) title21                        0.000827\n",
      "139) title67                        0.000777\n",
      "140) title18                        0.000771\n",
      "141) body&topic130                  0.000769\n",
      "142) body&topic143                  0.000765\n",
      "143) title68                        0.000750\n",
      "144) title46                        0.000716\n",
      "145) body&topic196                  0.000702\n",
      "146) title19                        0.000697\n",
      "147) body&topic113                  0.000693\n",
      "148) body&topic126                  0.000678\n",
      "149) title8                         0.000670\n",
      "150) title49                        0.000651\n",
      "151) title71                        0.000639\n",
      "152) body&topic181                  0.000621\n",
      "153) title53                        0.000617\n",
      "154) title0                         0.000617\n",
      "155) body&topic106                  0.000613\n",
      "156) title22                        0.000606\n",
      "157) title34                        0.000594\n",
      "158) body&topic155                  0.000541\n",
      "159) title11                        0.000522\n",
      "160) body&topic110                  0.000513\n",
      "161) title47                        0.000482\n",
      "162) title50                        0.000459\n",
      "163) title20                        0.000447\n",
      "164) body&topic186                  0.000444\n",
      "165) body&topic116                  0.000427\n",
      "166) body&topic164                  0.000426\n",
      "167) title62                        0.000416\n",
      "168) title3                         0.000415\n",
      "169) title23                        0.000414\n",
      "170) body&topic125                  0.000409\n",
      "171) body&topic200                  0.000399\n",
      "172) title44                        0.000387\n",
      "173) title54                        0.000385\n",
      "174) title33                        0.000382\n",
      "175) title10                        0.000379\n",
      "176) body&topic118                  0.000377\n",
      "177) title28                        0.000373\n",
      "178) body&topic193                  0.000373\n",
      "179) body&topic135                  0.000371\n",
      "180) title73                        0.000365\n",
      "181) title14                        0.000364\n",
      "182) title29                        0.000346\n",
      "183) title40                        0.000345\n",
      "184) title37                        0.000344\n",
      "185) body&topic136                  0.000327\n",
      "186) title75                        0.000326\n",
      "187) title9                         0.000318\n",
      "188) title4                         0.000313\n",
      "189) body&topic127                  0.000308\n",
      "190) body&topic128                  0.000308\n",
      "191) body&topic146                  0.000304\n",
      "192) body&topic187                  0.000294\n",
      "193) body&topic182                  0.000293\n",
      "194) body&topic109                  0.000293\n",
      "195) title36                        0.000288\n",
      "196) title59                        0.000281\n",
      "197) title52                        0.000272\n",
      "198) body&topic114                  0.000269\n",
      "199) title60                        0.000247\n",
      "200) body&topic123                  0.000244\n",
      "201) body&topic194                  0.000234\n",
      "202) title42                        0.000227\n",
      "203) body&topic165                  0.000223\n",
      "204) title61                        0.000220\n",
      "205) title69                        0.000217\n",
      "206) body&topic156                  0.000214\n",
      "207) body&topic177                  0.000201\n",
      "208) title55                        0.000187\n",
      "209) title39                        0.000185\n",
      "210) title70                        0.000184\n",
      "211) body&topic144                  0.000182\n",
      "212) title12                        0.000181\n",
      "213) body&topic154                  0.000181\n",
      "214) title57                        0.000179\n",
      "215) title15                        0.000176\n",
      "216) body&topic145                  0.000171\n",
      "217) title43                        0.000167\n",
      "218) title35                        0.000164\n",
      "219) title74                        0.000161\n",
      "220) body&topic149                  0.000160\n",
      "221) body&topic188                  0.000158\n",
      "222) body&topic161                  0.000147\n",
      "223) title5                         0.000142\n",
      "224) title32                        0.000142\n",
      "225) title65                        0.000142\n",
      "226) title51                        0.000136\n",
      "227) title41                        0.000136\n",
      "228) title7                         0.000129\n",
      "229) title1                         0.000128\n",
      "230) title6                         0.000126\n",
      "231) title24                        0.000124\n",
      "232) title13                        0.000123\n",
      "233) body&topic111                  0.000119\n",
      "234) title64                        0.000116\n",
      "235) body&topic190                  0.000114\n",
      "236) title56                        0.000113\n",
      "237) body&topic166                  0.000111\n",
      "238) body&topic157                  0.000109\n",
      "239) title48                        0.000108\n",
      "240) title38                        0.000104\n",
      "241) body&topic159                  0.000103\n",
      "242) title16                        0.000102\n",
      "243) body&topic171                  0.000099\n",
      "244) body&topic178                  0.000097\n",
      "245) body&topic198                  0.000093\n",
      "246) body&topic142                  0.000093\n",
      "247) body&topic134                  0.000085\n",
      "248) body&topic174                  0.000083\n",
      "249) title30                        0.000083\n",
      "250) body&topic167                  0.000080\n",
      "251) body&topic140                  0.000080\n",
      "252) body&topic150                  0.000078\n",
      "253) body&topic185                  0.000072\n",
      "254) title2                         0.000071\n",
      "255) body&topic132                  0.000063\n",
      "256) body&topic107                  0.000058\n",
      "257) title31                        0.000052\n",
      "258) title72                        0.000050\n",
      "259) body&topic124                  0.000050\n",
      "260) body&topic163                  0.000047\n",
      "261) body&topic129                  0.000046\n",
      "262) title17                        0.000045\n",
      "263) body&topic115                  0.000043\n",
      "264) body&topic197                  0.000040\n",
      "265) body&topic158                  0.000038\n",
      "266) body&topic183                  0.000034\n",
      "267) title66                        0.000034\n",
      "268) body&topic195                  0.000033\n",
      "269) title58                        0.000029\n",
      "270) body&topic162                  0.000027\n",
      "271) body&topic168                  0.000021\n",
      "272) body&topic108                  0.000020\n",
      "273) body&topic180                  0.000019\n",
      "274) body&topic184                  0.000019\n",
      "275) body&topic173                  0.000014\n",
      "276) body&topic179                  0.000012\n",
      "277) body&topic147                  0.000012\n",
      "278) body&topic152                  0.000007\n",
      "279) body&topic120                  0.000007\n",
      "280) body&topic172                  0.000006\n",
      "281) body&topic148                  0.000004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = forest.feature_importances_\n",
    "# get sort indices in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "listOfBody = []\n",
    "for i in range(201):\n",
    "    listOfBody.append(\"body&topic{0}\".format(i))\n",
    "\n",
    "listOfCate = []\n",
    "for i in range(76):\n",
    "    listOfCate.append(\"title{0}\".format(i))\n",
    "X_col_name = [\"Id\"]+listOfBody+['week of day', 'weekend', 'toEndOfYear']+listOfCate\n",
    "\n",
    "for f in range(new_feature_x.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            X_col_name[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(new_feature_x.shape[1]),\n",
    "        importances[indices],\n",
    "        align='center',\n",
    "        alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
